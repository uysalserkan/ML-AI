{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installing libraries\n",
    "import collections\n",
    "import pathlib\n",
    "import re\n",
    "import string\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras import preprocessing\n",
    "from tensorflow.keras import utils\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GLOBAL Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "SEED = 25\n",
    "VOCAB_SIZE = 10000\n",
    "MAX_SEQUENCE_LENGTH = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow-text in /home/red/.local/lib/python3.8/site-packages (2.4.2)\n",
      "Requirement already satisfied: tensorflow<2.5,>=2.4.0 in /home/red/.local/lib/python3.8/site-packages (from tensorflow-text) (2.4.0)\n",
      "Requirement already satisfied: tensorflow-hub>=0.8.0 in /home/red/.local/lib/python3.8/site-packages (from tensorflow-text) (0.10.0)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in /home/red/.local/lib/python3.8/site-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text) (1.12.1)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /home/red/.local/lib/python3.8/site-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text) (3.13.0)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in /home/red/.local/lib/python3.8/site-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text) (1.1.0)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in /home/red/.local/lib/python3.8/site-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text) (3.7.4.3)\n",
      "Requirement already satisfied: google-pasta~=0.2 in /home/red/.local/lib/python3.8/site-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text) (0.2.0)\n",
      "Requirement already satisfied: h5py~=2.10.0 in /home/red/.local/lib/python3.8/site-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text) (2.10.0)\n",
      "Requirement already satisfied: tensorboard~=2.4 in /home/red/.local/lib/python3.8/site-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text) (2.4.0)\n",
      "Requirement already satisfied: numpy~=1.19.2 in /home/red/.local/lib/python3.8/site-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text) (1.19.4)\n",
      "Requirement already satisfied: wheel~=0.35 in /home/red/.local/lib/python3.8/site-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text) (0.36.2)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in /home/red/.local/lib/python3.8/site-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text) (1.1.2)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in /home/red/.local/lib/python3.8/site-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text) (1.6.3)\n",
      "Requirement already satisfied: gast==0.3.3 in /home/red/.local/lib/python3.8/site-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text) (0.3.3)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in /home/red/.local/lib/python3.8/site-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text) (3.3.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0rc0 in /home/red/.local/lib/python3.8/site-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text) (2.4.0)\n",
      "Requirement already satisfied: grpcio~=1.32.0 in /home/red/.local/lib/python3.8/site-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text) (1.32.0)\n",
      "Requirement already satisfied: six~=1.15.0 in /home/red/.local/lib/python3.8/site-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text) (1.15.0)\n",
      "Requirement already satisfied: absl-py~=0.10 in /home/red/.local/lib/python3.8/site-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text) (0.10.0)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in /home/red/.local/lib/python3.8/site-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text) (1.12)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from protobuf>=3.9.2->tensorflow<2.5,>=2.4.0->tensorflow-text) (45.2.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/red/.local/lib/python3.8/site-packages (from tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text) (1.7.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/lib/python3/dist-packages (from tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text) (2.22.0)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /home/red/.local/lib/python3.8/site-packages (from tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text) (1.22.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/red/.local/lib/python3.8/site-packages (from tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text) (0.4.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/red/.local/lib/python3.8/site-packages (from tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text) (3.3.2)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/red/.local/lib/python3.8/site-packages (from tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text) (1.0.1)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /home/red/.local/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text) (4.1.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/red/.local/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.5\" in /home/red/.local/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text) (4.6)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/red/.local/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/red/.local/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/lib/python3/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text) (3.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install tensorflow-text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_text as tf_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/stack_overflow_16k.tar.gz\n",
      "6053888/6053168 [==============================] - 2s 0us/step\n"
     ]
    }
   ],
   "source": [
    "data_url = 'https://storage.googleapis.com/download.tensorflow.org/data/stack_overflow_16k.tar.gz'\n",
    "dataset = utils.get_file(\n",
    "    'stack_overflow_16k.tar.gz',\n",
    "    data_url,\n",
    "    untar=True,\n",
    "    cache_dir='stack_overflow',\n",
    "    cache_subdir=''\n",
    ")\n",
    "dataset_dir = pathlib.Path(dataset).parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/tmp/.keras/README.md'),\n",
       " PosixPath('/tmp/.keras/test'),\n",
       " PosixPath('/tmp/.keras/train'),\n",
       " PosixPath('/tmp/.keras/stack_overflow_16k.tar.gz.tar.gz')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(dataset_dir.iterdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/tmp/.keras/train/csharp'),\n",
       " PosixPath('/tmp/.keras/train/javascript'),\n",
       " PosixPath('/tmp/.keras/train/python'),\n",
       " PosixPath('/tmp/.keras/train/java')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define train folder\n",
    "train_dir = dataset_dir/'train'\n",
    "list(train_dir.iterdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"error in cv::imshow i am trying to run this blank program but it gives an error..i don't understand what is the error and how to solve it...error:..error: ........opencvmoduleshighguisrcwindow.cpp:261: error: (-215) .    size.width&gt;0 &amp;&amp; size.height&gt;0 .in function cv::imshow...source code:..import cv2.import matplotlib.pyplot as plt..#original img.img = cv2.imread('1.jpeg').#gray img.img1 = cv2.imread('1.jpeg',0).#display img.cv2.imshow('img',img)..cv2.imshow('gray img',img1)..#view image size or shape.print (img.shape).print(img1.size)..#number of pixels.print(img.size).print(img1.size).#graph .\"\"\"\"\"\".x1=[6,2,4,3].x2=[2,3,4,5].plt.scatter(x1,x2).plt.show().\"\"\"\"\"\"..#write an image.cv2.imwrite('gray_image.jpeg',img1)..#access specific index.print(img[150,150])..#modify the pixel value.img[150,150] = 30.print (img[150,150])..#crop image.crop = img[100:150,100:150]..cv2.imshow('cropped image',crop)..#img will display till press the enter.cv2.waitkey(0)...the error is in line: cv2.imshow('img',img)\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sample = train_dir/'python/25.txt'\n",
    "with open(sample) as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 files belonging to 4 classes.\n",
      "Using 6400 files for training.\n"
     ]
    }
   ],
   "source": [
    "raw_train_ds = preprocessing.text_dataset_from_directory(\n",
    "    train_dir,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    validation_split=0.2,\n",
    "    subset='training',\n",
    "    seed=SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:  b'\"blank only - sort a bunch of divs .  possible duplicate:.  easiest way to sort dom nodes?  .....i h' ...\n",
      "Label:  2\n",
      "Question:  b'blank- document/window has focus? .  possible duplicate:.  how do i find out which blank element has' ...\n",
      "Label:  2\n",
      "Question:  b'\"making a pyramide trying to make a pyramide here, but i\\'m new to blank and a little stuck...the pyr' ...\n",
      "Label:  1\n",
      "Question:  b'\"is this creating 12 string objects? i\\'m trying to understand if this code below creates 12 objects ' ...\n",
      "Label:  1\n",
      "Question:  b'\"tabs n in list for blank i have simple script in blank, want return per line the values..tabs = # a' ...\n",
      "Label:  3\n",
      "Question:  b'\"typeerror: \\'dict_values\\' object does not support indexing while calling layer from combo box- pyqgi' ...\n",
      "Label:  3\n",
      "Question:  b'\"blank- have to model a circle okay so i don\\'t know if any of you like helping homework at all, but ' ...\n",
      "Label:  1\n",
      "Question:  b'\"how can i pass function\\'s return value as parameter? i have lots of functions similar to functionon' ...\n",
      "Label:  2\n",
      "Question:  b'\"what is wrong with the iterator for a tree data structure? i am trying to implement a naive iterato' ...\n",
      "Label:  2\n",
      "Question:  b'\"unable to loop through documents strings i feel i am missing something here and i was hoping someon' ...\n",
      "Label:  0\n"
     ]
    }
   ],
   "source": [
    "for text_batch, label_batch in raw_train_ds.take(1):\n",
    "    for i in range(10):\n",
    "        print(\"Question: \", text_batch.numpy()[i][:100], '...')\n",
    "        print(\"Label: \", label_batch.numpy()[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 0 \tCorresponds to: csharp\n",
      "Label: 1 \tCorresponds to: java\n",
      "Label: 2 \tCorresponds to: javascript\n",
      "Label: 3 \tCorresponds to: python\n"
     ]
    }
   ],
   "source": [
    "for i, label in enumerate(raw_train_ds.class_names):\n",
    "    print(\"Label: {} \\tCorresponds to: {}\".format(i, label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 files belonging to 4 classes.\n",
      "Using 1600 files for validation.\n"
     ]
    }
   ],
   "source": [
    "raw_val_ds = preprocessing.text_dataset_from_directory(\n",
    "    train_dir,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    validation_split=0.2,\n",
    "    subset='validation',\n",
    "    seed=SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 files belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "test_dir = dataset_dir/'test'\n",
    "raw_test_ds = preprocessing.text_dataset_from_directory(\n",
    "    test_dir, \n",
    "    batch_size=BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_vectorize_layer = TextVectorization(\n",
    "    max_tokens=VOCAB_SIZE,\n",
    "    output_mode='binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_vectorize_layer = TextVectorization(\n",
    "    max_tokens=VOCAB_SIZE,\n",
    "    output_mode='int',\n",
    "    output_sequence_length=MAX_SEQUENCE_LENGTH\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text = raw_train_ds.map(lambda text, labels: text)\n",
    "binary_vectorize_layer.adapt(train_text)\n",
    "int_vectorize_layer.adapt(train_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_vectorize_text(text, label):\n",
    "    text = tf.expand_dims(text, -1)\n",
    "    return binary_vectorize_layer(text), label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": [
     "Serkan"
    ]
   },
   "outputs": [],
   "source": [
    "def int_vectorize_text(text, label):\n",
    "    text = tf.expand_dims(text, -1)\n",
    "    return int_vectorize_layer(text), label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: b'\"blank comparing parentheses from user input and making sure they have a pair i\\'m writing a program to take a user input of parentheses i.e. {} [] () and checking to see if they have a pair (opening and closing). i\\'m running into an error when running my code where i always get the return false. i\\'ve tried different ways of checking against a pre set \"\"list\"\" but it doesn\\'t seem to work. i have to use the class from above too. any help is appreciated. ..some example inputs are:..    &gt;&gt;&gt;parenthesesmatch(\\'{[]}\\').    true.    &gt;&gt;&gt;parenthesesmatch(\\'({})\\').    true.    &gt;&gt;&gt;parenthesesmatch(\\'{[)]}\\').    false...my code:..    #george flamburis...class stack():.def __init__(self,que=[]):.    self.lst = que.def __repr__(self):.    return \"\"stack({})\"\".format(self.lst).def push(self, add):.    self.lst.append(add).def pop(self):.    return self.lst.pop().def isempty(self):.    return self.lst==[].def first(self, loc=0):            #naming of this method can\\'t be [].    return self.lst[loc].def len(self):.    return len(self.lst)..def parenthesesmatch(match):.     s = stack().     end = [].     for char in match:.         if char in \"\"[ { (\"\":.             s.push(char).         else:.             end.append(char)..     if s.len()==len(end):.             for num in range(len(end)):.                     if s.first(num) and end[num] not in \\'[]\\' or \\'{}\\' or\\'()\\':.                             return false.             return true.     elif s.len()!=len(end):.             return false\"\\n'\n",
      "\n",
      "Label: 3\n"
     ]
    }
   ],
   "source": [
    "# Retrieve a batch from the dataset\n",
    "text_batch, label_batch = next(iter(raw_train_ds))\n",
    "first_question, first_label = text_batch[0], label_batch[0]\n",
    "\n",
    "print(\"Question: {}\".format(first_question))\n",
    "print(\"\\nLabel: {}\".format(first_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'binary' vectorized question: tf.Tensor([[1. 1. 1. ... 0. 0. 0.]], shape=(1, 10000), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(\"'binary' vectorized question:\", \n",
    "      binary_vectorize_text(first_question, first_label)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'int' vectorized question: tf.Tensor(\n",
      "[[  16 1091 3851   32   99   91    8  462  223  195   17    5 1312   51\n",
      "   408    5   87    4  353    5   99   91    9 3851  421    8  790    4\n",
      "   184   11  195   17    5 1312 1805    8 2015   51  292   97   31   67\n",
      "    46  292   23   29  132    3  343   41    2   26  106  193  145  182\n",
      "   948    9  790 1563    5 6301  103   59   27   10  185  495    4  137\n",
      "     3   17    4   71    2   30   32  251  433   76  107    6  562   85\n",
      "   142  762   61    1   89    1   89    1    1   29 3658    1    1    1\n",
      "     1    1 4989   26    1    1  122    1    1   26    1    1   26    1\n",
      "     1    1 5068    9   13   64  166   33   26    1 7651   26    1    1\n",
      "   176  837  206   12  283    7  653   11  283    7    1   53    1   11\n",
      "     1   12  344    7    1   11    1    8    1   21    7   45   45   26\n",
      "   106   26   89  287    1   26  106    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0]], shape=(1, 250), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "print(\"'int' vectorized question:\",\n",
    "      int_vectorize_text(first_question, first_label)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1289 --->  report\n",
      "313 --->  put\n",
      "Vocabulary size: 10000\n"
     ]
    }
   ],
   "source": [
    "print(\"1289 ---> \", int_vectorize_layer.get_vocabulary()[1289])\n",
    "print(\"313 ---> \", int_vectorize_layer.get_vocabulary()[313])\n",
    "print(\"Vocabulary size: {}\".format(len(int_vectorize_layer.get_vocabulary())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating clusters\n",
    "binary_train_ds = raw_train_ds.map(binary_vectorize_text)\n",
    "binary_val_ds = raw_val_ds.map(binary_vectorize_text)\n",
    "binary_test_ds = raw_test_ds.map(binary_vectorize_text)\n",
    "\n",
    "int_train_ds = raw_train_ds.map(int_vectorize_text)\n",
    "int_val_ds = raw_val_ds.map(int_vectorize_text)\n",
    "int_test_ds = raw_test_ds.map(int_vectorize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "def configure_dataset(dataset):\n",
    "  return dataset.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuring sets\n",
    "binary_train_ds = configure_dataset(binary_train_ds)\n",
    "binary_val_ds = configure_dataset(binary_val_ds)\n",
    "binary_test_ds = configure_dataset(binary_test_ds)\n",
    "\n",
    "int_train_ds = configure_dataset(int_train_ds)\n",
    "int_val_ds = configure_dataset(int_val_ds)\n",
    "int_test_ds = configure_dataset(int_test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_model = tf.keras.Sequential([layers.Dense(4)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_model.compile(\n",
    "    loss=losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.2699 - accuracy: 0.9538 - val_loss: 0.4840 - val_accuracy: 0.8256\n",
      "Epoch 2/25\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.2510 - accuracy: 0.9577 - val_loss: 0.4783 - val_accuracy: 0.8250\n",
      "Epoch 3/25\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.2342 - accuracy: 0.9614 - val_loss: 0.4738 - val_accuracy: 0.8238\n",
      "Epoch 4/25\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.2191 - accuracy: 0.9653 - val_loss: 0.4704 - val_accuracy: 0.8250\n",
      "Epoch 5/25\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.2053 - accuracy: 0.9698 - val_loss: 0.4678 - val_accuracy: 0.8250\n",
      "Epoch 6/25\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.1928 - accuracy: 0.9734 - val_loss: 0.4660 - val_accuracy: 0.8256\n",
      "Epoch 7/25\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.1813 - accuracy: 0.9758 - val_loss: 0.4648 - val_accuracy: 0.8250\n",
      "Epoch 8/25\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.1707 - accuracy: 0.9786 - val_loss: 0.4641 - val_accuracy: 0.8250\n",
      "Epoch 9/25\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.1610 - accuracy: 0.9806 - val_loss: 0.4639 - val_accuracy: 0.8225\n",
      "Epoch 10/25\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.1519 - accuracy: 0.9828 - val_loss: 0.4642 - val_accuracy: 0.8219\n",
      "Epoch 11/25\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.1435 - accuracy: 0.9855 - val_loss: 0.4648 - val_accuracy: 0.8213\n",
      "Epoch 12/25\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.1357 - accuracy: 0.9867 - val_loss: 0.4658 - val_accuracy: 0.8206\n",
      "Epoch 13/25\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.1284 - accuracy: 0.9880 - val_loss: 0.4671 - val_accuracy: 0.8200\n",
      "Epoch 14/25\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.1216 - accuracy: 0.9897 - val_loss: 0.4686 - val_accuracy: 0.8188\n",
      "Epoch 15/25\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.1152 - accuracy: 0.9903 - val_loss: 0.4705 - val_accuracy: 0.8175\n",
      "Epoch 16/25\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.1092 - accuracy: 0.9908 - val_loss: 0.4725 - val_accuracy: 0.8163\n",
      "Epoch 17/25\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.1036 - accuracy: 0.9912 - val_loss: 0.4748 - val_accuracy: 0.8163\n",
      "Epoch 18/25\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.0983 - accuracy: 0.9919 - val_loss: 0.4773 - val_accuracy: 0.8156\n",
      "Epoch 19/25\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.0933 - accuracy: 0.9925 - val_loss: 0.4800 - val_accuracy: 0.8156\n",
      "Epoch 20/25\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.0885 - accuracy: 0.9931 - val_loss: 0.4829 - val_accuracy: 0.8144\n",
      "Epoch 21/25\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.0841 - accuracy: 0.9934 - val_loss: 0.4859 - val_accuracy: 0.8138\n",
      "Epoch 22/25\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.0799 - accuracy: 0.9942 - val_loss: 0.4891 - val_accuracy: 0.8138\n",
      "Epoch 23/25\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.0759 - accuracy: 0.9953 - val_loss: 0.4925 - val_accuracy: 0.8131\n",
      "Epoch 24/25\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.0722 - accuracy: 0.9955 - val_loss: 0.4959 - val_accuracy: 0.8125\n",
      "Epoch 25/25\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.0686 - accuracy: 0.9959 - val_loss: 0.4996 - val_accuracy: 0.8119\n"
     ]
    }
   ],
   "source": [
    "history = binary_model.fit(binary_train_ds, validation_data=binary_val_ds, epochs=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a model with `int vector`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(vocab_size, num_labels):\n",
    "    model=tf.keras.Sequential([\n",
    "        layers.Embedding(vocab_size, 64, mask_zero=True),\n",
    "        layers.Conv1D(64, 5, padding='valid', activation='relu', strides=2),\n",
    "        layers.GlobalMaxPool1D(),\n",
    "        layers.Dense(num_labels)\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_model = create_model(vocab_size=VOCAB_SIZE + 1, num_labels=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_model.compile(\n",
    "    loss=losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "200/200 [==============================] - 3s 12ms/step - loss: 1.3119 - accuracy: 0.4132 - val_loss: 0.7738 - val_accuracy: 0.6975\n",
      "Epoch 2/10\n",
      "200/200 [==============================] - 2s 10ms/step - loss: 0.6879 - accuracy: 0.7328 - val_loss: 0.5243 - val_accuracy: 0.8012\n",
      "Epoch 3/10\n",
      "200/200 [==============================] - 2s 10ms/step - loss: 0.4080 - accuracy: 0.8677 - val_loss: 0.4484 - val_accuracy: 0.8256\n",
      "Epoch 4/10\n",
      "200/200 [==============================] - 2s 10ms/step - loss: 0.2261 - accuracy: 0.9455 - val_loss: 0.4376 - val_accuracy: 0.8300\n",
      "Epoch 5/10\n",
      "200/200 [==============================] - 2s 10ms/step - loss: 0.1102 - accuracy: 0.9840 - val_loss: 0.4557 - val_accuracy: 0.8256\n",
      "Epoch 6/10\n",
      "200/200 [==============================] - 2s 10ms/step - loss: 0.0485 - accuracy: 0.9959 - val_loss: 0.4785 - val_accuracy: 0.8206\n",
      "Epoch 7/10\n",
      "200/200 [==============================] - 2s 10ms/step - loss: 0.0223 - accuracy: 0.9998 - val_loss: 0.5017 - val_accuracy: 0.8213\n",
      "Epoch 8/10\n",
      "200/200 [==============================] - 2s 10ms/step - loss: 0.0120 - accuracy: 1.0000 - val_loss: 0.5237 - val_accuracy: 0.8213\n",
      "Epoch 9/10\n",
      "200/200 [==============================] - 2s 10ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.5435 - val_accuracy: 0.8225\n",
      "Epoch 10/10\n",
      "200/200 [==============================] - 2s 10ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.5611 - val_accuracy: 0.8225\n"
     ]
    }
   ],
   "source": [
    "history = int_model.fit(int_train_ds, validation_data=int_val_ds, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary vs. Int model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear model on binary vectorized data:\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 4)                 40004     \n",
      "=================================================================\n",
      "Total params: 40,004\n",
      "Trainable params: 40,004\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(\"Linear model on binary vectorized data:\")\n",
    "print(binary_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvNet model on int vectorized data:\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, None, 64)          640064    \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, None, 64)          20544     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4)                 260       \n",
      "=================================================================\n",
      "Total params: 660,868\n",
      "Trainable params: 660,868\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(\"ConvNet model on int vectorized data:\")\n",
    "print(int_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 1s 3ms/step - loss: 0.5221 - accuracy: 0.7991\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.6183 - accuracy: 0.8164\n",
      "Binary model accuracy: 79.91%\n",
      "Int model accuracy: 81.64%\n"
     ]
    }
   ],
   "source": [
    "binary_loss, binary_accuracy = binary_model.evaluate(binary_test_ds)\n",
    "int_loss, int_accuracy = int_model.evaluate(int_test_ds)\n",
    "\n",
    "print(\"Binary model accuracy: {:2.2%}\".format(binary_accuracy))\n",
    "print(\"Int model accuracy: {:2.2%}\".format(int_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_model = tf.keras.Sequential([\n",
    "    binary_vectorize_layer, \n",
    "    binary_model,\n",
    "    layers.Activation('sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_model.compile(\n",
    "    loss=losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 1s 4ms/step - loss: 0.5221 - accuracy: 0.7991\n",
      "Accuracy: 79.91%\n"
     ]
    }
   ],
   "source": [
    "loss, acc = export_model.evaluate(raw_test_ds)\n",
    "print(\"Accuracy: {:2.2%}\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function for calculating label\n",
    "def get_string_labels(predicted_scores_batch):\n",
    "    predicted_int_labels = tf.argmax(predicted_scores_batch, axis=1)\n",
    "    predicted_label = tf.gather(raw_train_ds.class_names, predicted_int_labels)\n",
    "    return predicted_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:  how do I extract keys from a dict into a list?\n",
      "Predicted label:  b'python'\n",
      "Question:  debug public static void main(string[] args) {...}\n",
      "Predicted label:  b'java'\n"
     ]
    }
   ],
   "source": [
    "inputs = [\n",
    "    \"how do I extract keys from a dict into a list?\",  # python\n",
    "    \"debug public static void main(string[] args) {...}\",  # java\n",
    "]\n",
    "predicted_scores = export_model.predict(inputs)\n",
    "predicted_labels = get_string_labels(predicted_scores)\n",
    "for input, label in zip(inputs, predicted_labels):\n",
    "  print(\"Question: \", input)\n",
    "  print(\"Predicted label: \", label.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted label: [b'csharp' b'csharp' b'python']\n"
     ]
    }
   ],
   "source": [
    "# input text link: https://stackoverflow.com/questions/65482724/how-to-copy-byte-data-into-a-very-large-float\n",
    "input_text = [\n",
    "    \"\"\"I am trying to copy byte[] data into a float[] like this:\n",
    "\n",
    "float[] floatArr = new float[int32.MaxValue];\n",
    "byte[] byteArr = new byte[bufferSize];\n",
    "// fill buffer\n",
    "Buffer.BlockCopy(byteArr, 0, floatArr, 0, bufferSize);\n",
    "This works fine, because I am copying it to the start of the destination array. But how can I copy the data to an index greater than int32.MaxValue?\"\"\", \n",
    "    # text link: https://stackoverflow.com/questions/65482724/how-to-copy-byte-data-into-a-very-large-float\n",
    "    \"\"\"I am trying to rewrite some old vb6 code using C-sharp. The problem is that when I used FloodFill in vb it saves the image with the affect of FloodFill. This is not true using C-sharp. Here is the code segment for VB6:\"\"\",\n",
    "    # text link: https://stackoverflow.com/questions/65451723/floodfill-using-c-sharp\n",
    "    \"\"\"I am creating a math game and want a score count in the top corner.\n",
    "\n",
    "I have created the labels:\n",
    "\n",
    "score = 0\n",
    "\n",
    "score_addition_easy_label = Label(root7, text=\"Score count: \")\n",
    "score_addition_easy_label.place(x=25, y=100)\n",
    "\n",
    "score_addition_easy_number = Label(root7, text=score)\n",
    "score_addition_easy_number.place(x=120, y=100)\n",
    "when the code is run it displays:\"\"\", \n",
    "    # text link: https://stackoverflow.com/questions/65482933/how-to-change-the-text-of-a-label-tkinter\n",
    "]\n",
    "\n",
    "pred = export_model.predict(input_text)\n",
    "pred_l = get_string_labels(pred)\n",
    "\n",
    "print(\"Predicted label: {}\".format(pred_l))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Burada KaldÄ±k](https://www.tensorflow.org/tutorials/load_data/text#example_2_predict_the_author_of_illiad_translations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc-autonumbering": true,
  "toc-showcode": true,
  "toc-showmarkdowntxt": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
